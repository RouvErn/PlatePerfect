{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Assumptions:\n",
    "# - `df_images` is a DataFrame with image paths and IDs\n",
    "# - `df_ingredients` is a DataFrame with ingredients information and IDs\n",
    "# - `your_label_columns` are the columns representing the ingredients information in the DataFrame\n",
    "\n",
    "# Merge both DataFrames based on the image IDs\n",
    "merged_df = pd.merge(df_images, df_ingredients, on='image_id')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data generators for images\n",
    "'''train_datagen is used to generate data for training the model by reading images from a directory, performing transformations, and normalization.\n",
    "\n",
    "ImageDataGenerator is a class in TensorFlow/Keras that generates batches of augmented/normalized data from image data.\n",
    "It provides a flexible way to preprocess and augment images on-the-fly during training, without needing to pre-process and store all the images in memory.'''\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "'''The train_generator generates batches of augmented/normalized data from image data and labels in the form of a DataFrame.\n",
    "In the provided code, the train_generator is specifically responsible for generating training data for the model.\n",
    "It generates batches of data from the DataFrame train_df, which contains information about image paths and corresponding labels (ingredients in this case).'''\n",
    "\n",
    "#VARIABLES in train_generator:\n",
    "'''The \"image_path\" parameter in the flow_from_dataframe() method indicates which column of the DataFrame contains the paths to the images.\n",
    "When you provide this parameter, the ImageDataGenerator will use the paths specified in that column to load the images for processing.'''\n",
    "\n",
    "'''your_label_columns represents the column(s) in your DataFrame that contain the labels or target variables for your classification task.\n",
    "In the context of the provided code, it indicates the column(s) that contain information about the ingredients or classes associated with each image.'''\n",
    "\n",
    "'''batch_size is a hyperparameter that determines the number of samples processed by the model in each training iteration or batch during the training process.'''\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=your_label_columns,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=your_label_columns,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "'''num_channels typically refers to the number of channels or color channels in an image.\n",
    "\n",
    "In the context of the provided code, num_channels specifies the number of color channels for the input images. For example:\n",
    "\n",
    "For grayscale images, num_channels would be 1.\n",
    "For RGB (Red, Green, Blue) color images, num_channels would be 3, as there are three color channels representing the intensity of each color.'''\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, num_channels)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')           #num_classes is = number of ingredients\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
